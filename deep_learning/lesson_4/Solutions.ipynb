{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82d52145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "\n",
    "        _, y_pred = torch.max(output, 1)\n",
    "        \n",
    "        predictions.append(y_pred)\n",
    "        \n",
    "    print(\"x\", x)\n",
    "    \n",
    "    print(\"y\", y)\n",
    "    \n",
    "    print(\"output\", output)\n",
    "    \n",
    "    print(\"_\", _)\n",
    "        \n",
    "    print(\"y_pred\", y_pred)\n",
    "    \n",
    "    print(\"predictions\", torch.cat(predictions))\n",
    "    \n",
    "    return torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "426e2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "y tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "output tensor([[ 4.4107e-02,  7.0509e-02, -2.2490e-01, -8.0287e-02,  2.8912e-02,\n",
      "         -4.6159e-02, -1.3146e-01,  1.5648e-02, -9.9098e-02, -7.5260e-02],\n",
      "        [ 4.5122e-02,  7.2099e-02, -2.3913e-01, -8.2015e-02,  9.5956e-02,\n",
      "         -2.2497e-01, -8.4134e-02, -5.5596e-02, -1.6116e-01, -5.2191e-02],\n",
      "        [-4.9748e-02,  9.2228e-02, -2.1303e-01, -7.1199e-02,  5.5251e-02,\n",
      "         -1.2299e-01, -5.9711e-02,  4.7511e-02, -1.6293e-01, -6.7945e-02],\n",
      "        [ 1.7605e-02,  9.7434e-02, -8.5352e-02,  2.9700e-02,  9.1059e-02,\n",
      "         -1.7828e-01, -1.1840e-01,  4.3439e-03, -1.5029e-01, -7.8184e-02],\n",
      "        [ 3.4225e-02,  9.9104e-02, -1.6251e-01, -6.0276e-02,  2.7459e-02,\n",
      "         -2.0729e-01, -8.2457e-02, -1.8970e-02, -1.4955e-01, -9.0903e-02],\n",
      "        [ 6.9209e-03,  5.8254e-02, -2.7545e-01, -1.2193e-02,  5.1431e-02,\n",
      "         -1.0473e-01, -1.5329e-01,  1.4945e-02, -1.9011e-01, -1.5503e-01],\n",
      "        [ 4.3712e-02,  1.0384e-01, -2.2848e-01, -2.2221e-03,  5.9675e-02,\n",
      "         -1.7652e-01, -1.3239e-01, -3.2972e-02, -1.6403e-01, -1.0719e-01],\n",
      "        [-5.5184e-02,  9.1114e-02, -2.0924e-01, -6.0487e-02,  8.2696e-03,\n",
      "         -2.0645e-01, -4.5451e-02,  1.1221e-01, -1.3572e-01, -5.6201e-02],\n",
      "        [-6.8884e-03,  1.4365e-01, -9.5259e-02, -2.5347e-02,  7.4829e-02,\n",
      "         -3.5058e-02, -6.5042e-02, -7.6908e-02, -5.9768e-02, -7.5726e-02],\n",
      "        [-1.9148e-02,  1.2733e-01, -2.5957e-01,  4.3133e-02,  6.4471e-02,\n",
      "         -1.8733e-01, -1.5205e-01, -3.9582e-03, -1.2608e-01, -8.4330e-02],\n",
      "        [ 1.2284e-02,  5.5310e-02, -2.1154e-01, -1.1732e-01,  1.4400e-02,\n",
      "         -2.5023e-02, -1.3018e-01,  8.9471e-02, -1.4938e-01, -8.7864e-02],\n",
      "        [ 1.4540e-02,  9.9894e-02, -2.1233e-01,  4.9684e-02,  1.4597e-01,\n",
      "         -1.7698e-01, -6.0609e-02,  4.6283e-03, -1.4900e-01, -8.3860e-03],\n",
      "        [ 3.5716e-02,  8.3697e-02, -1.9707e-01, -1.4779e-01,  1.1316e-01,\n",
      "         -1.3744e-01, -5.4607e-02,  6.2253e-02, -1.1629e-01, -1.2550e-01],\n",
      "        [ 6.7159e-02,  1.0480e-01, -1.8038e-01, -1.8334e-02,  1.0548e-01,\n",
      "         -9.7534e-02, -1.5845e-01,  4.6056e-02, -1.3024e-01, -9.3284e-02],\n",
      "        [-7.9039e-05,  1.1636e-01, -1.7926e-01,  5.9335e-02,  1.1158e-01,\n",
      "         -1.2116e-01, -1.4474e-01,  4.7706e-02, -1.4090e-01, -1.2607e-01],\n",
      "        [ 6.7067e-02,  8.3110e-02, -2.5890e-01, -8.4367e-02,  1.0289e-01,\n",
      "         -6.8870e-02, -6.4546e-02,  2.6770e-05, -1.3817e-01, -8.6417e-02]],\n",
      "       device='cuda:0')\n",
      "_ tensor([0.0705, 0.0960, 0.0922, 0.0974, 0.0991, 0.0583, 0.1038, 0.1122, 0.1436,\n",
      "        0.1273, 0.0895, 0.1460, 0.1132, 0.1055, 0.1164, 0.1029],\n",
      "       device='cuda:0')\n",
      "y_pred tensor([1, 4, 1, 1, 1, 1, 1, 7, 1, 1, 7, 4, 4, 4, 1, 4], device='cuda:0')\n",
      "predictions tensor([1, 1, 1,  ..., 4, 1, 4], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 4, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "first_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(first_model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mnist_valid = MNIST(\n",
    "    \"../datasets/mnist\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(mnist_valid, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "first_model = first_model.to(device)\n",
    "\n",
    "predict(first_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1435ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2):\n",
    "    model.eval()\n",
    "    \n",
    "    iteration_outputs = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        outputs = []\n",
    "        \n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            outputs.append(output)\n",
    "            \n",
    "        iteration_outputs.append(torch.cat(outputs, 0))\n",
    "    \n",
    "    final_outputs = torch.stack(iteration_outputs, 0).mean(0)\n",
    "    \n",
    "    _, y_pred = torch.max(final_outputs, 1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee47c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4785, 0.1371, 0.3675],\n",
      "        [0.5567, 0.3634, 0.3025]])\n",
      "tensor([[0.7830, 0.6189, 0.5527],\n",
      "        [0.6542, 0.5239, 0.6354]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_1 = torch.rand(2, 3)\n",
    "print(t_1)\n",
    "\n",
    "t_2 = torch.rand(2, 3)\n",
    "print(t_2)\n",
    "\n",
    "torch.cat([t_1, t_2], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1867842c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4785, 0.1371, 0.3675],\n",
       "         [0.5567, 0.3634, 0.3025]],\n",
       "\n",
       "        [[0.7830, 0.6189, 0.5527],\n",
       "         [0.6542, 0.5239, 0.6354]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([t_1, t_2],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dbb0f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6308, 0.3780, 0.4601],\n",
       "        [0.6054, 0.4437, 0.4689]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([t_1, t_2],0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eafc1249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63075"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.4785 + 0.7830) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a121235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 5,  ..., 2, 6, 6], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "first_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(first_model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mnist_valid = MNIST(\n",
    "    \"../datasets/mnist\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(mnist_valid, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "first_model = first_model.to(device)\n",
    "\n",
    "predict_tta(first_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3484a2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tta(first_model, valid_loader, device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1b89243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "#!g1.1\n",
    "@torch.inference_mode()\n",
    "def evaluate_tta(model, loader, device: torch.device, iterations: int = 2) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    iteration_outputs = []\n",
    "    final_y = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        outputs = []\n",
    "        ys = []\n",
    "        \n",
    "        for x, y in tqdm(loader, desc='Evaluation'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            outputs.append(output)\n",
    "            ys.append(y)\n",
    "            \n",
    "        iteration_outputs.append(torch.cat(outputs, 0))\n",
    "    \n",
    "    final_outputs = torch.stack(iteration_outputs, 0).mean(0)\n",
    "    final_y = torch.cat(ys, 0)\n",
    "    \n",
    "    loss = loss_fn(final_outputs, final_y)\n",
    "    \n",
    "    _, y_pred = torch.max(final_outputs, 1)\n",
    "    \n",
    "    total += final_y.size(0)\n",
    "    correct += (y_pred == final_y).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85862e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 147.83it/s]\n",
      "Evaluation: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 146.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.3077, device='cuda:0'), 0.1141)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tta(first_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f7bea8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21153846153846154"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5/13 + 1/4) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4fbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
